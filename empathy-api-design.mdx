## 1. Overview

This document outlines the API for iCentant Empathyâ„¢, an LLM-powered empathy system that can analyze text input and generate empathetic output with text, images, and audio.

The output can either be an echo of the input using a different modality, an enhancement of the input using multiple modalities, an empathetic response to the input using multiple modalities.

The platform is currently in preview. Send email to <a href="mailto:support@icendant.com">support@icendant.com</a> if you would like to participate in our early access program.

## 2. API Endpoints

### Primary Endpoint

```
POST https://api.example.com/v1/empathy/generate
```

## 3. Request Structure

```json
{
  "model": "empathy-v1",
  "system": "<your system prompt - only used is empathy mode is 'complete'>",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "I'm feeling really stressed about my presentation tomorrow."
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "Presentations can be challenging."
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "I'm worried I'll forget what to say and everyone will judge me."
        }
      ]
    }
  ],
  "empathy_options": {
    "modes": ["text", "image", "audio"],
    "operation": "complete",
    "format": "vdom",
    "async": "await"
  },
  "parameters": {
    "temperature": 0.7,
    "max_tokens": 1024
  }
}
```

## 4. Response Structure

```json
{
  "id": "resp_8f7h2j3k4l5m6n7o8p9q0r",
  "created_at": "2025-03-26T14:30:45Z",
  "response": {
    "completion": {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "I can see that you're feeling anxious about your presentation tomorrow. It's completely normal to feel nervous before presenting. Remember that most people in the audience are supportive and want to see you succeed. Try practicing your key points a few more times tonight, and consider some deep breathing exercises right before the presentation to help calm your nerves. You've prepared for this, and you know your material - I believe in you!"
        },
        {
          "type": "image",
          "source": {
            "type": "generation",
            "uri": "https://api.example.com/images/resp_8f7h2j3k4l5m6n7o8p9q0r.png"
          }
        },
        {
          "type": "audio",
          "source": {
            "type": "generation", 
            "uri": "https://api.example.com/audio/resp_8f7h2j3k4l5m6n7o8p9q0r.mp3"
          }
        }
      ]
    }
  }
}
```

## 5. Field Descriptions

### 5.1 Request Fields

| Field | Type | Description                                                                                        |
|-------|------|----------------------------------------------------------------------------------------------------|
| `model` | string | Identifier for the empathy model version to use                                                    |
| `system` | string | System instructions that set the context and behavior for the model when mode is set to 'complete' |
| `messages` | array | Conversation history between user and assistant                                                    |
| `empathy_options` | object | Configuration for the desired response format                                                      |
| `parameters` | object | Model parameter settings                                                                           |

#### 5.1.1 Messages Structure

Each message object contains:

| Field | Type | Description |
|-------|------|-------------|
| `role` | string | Either "user", "assistant", or "system" |
| `content` | array | Array of content objects (only text is supported) |

Each content object contains:

| Field | Type | Description |
|-------|------|-------------|
| `type` | string | Content type: "text" only |
| `text` | string | The text content |

## 5.1.2 Empathy Options

| Field | Type | Description |
|-------|------|-------------|
| `modes` | array | Array of content modes to include in the response (text, image, audio) |
| `operation` | string | Processing mode: "complete", "enhance", or "echo" (default: "echo") |
| `format` | string | Output format for structured content: "html" or "vdom" (default: "vdom") |
| `async` | string | Asynchronous processing mode: "await" or "poll" (default: "await") |

### Example empathy_options Object

```json
"empathy_options": {
  "modes": ["text", "image"],
  "operation": "complete",
  "format": "vdom",
  "async": "await"
}
```

### Field Details

- **operation**: Determines the processing mode for the request:
  - `echo`: Generates a response based on the current message content only (default).
  - `enhance`: Improves the empathy of response based on the conversation flow.
  - `complete`: Performs a comprehensive analysis of the entire conversation history to provide a deeply contextual response.

- **format**: Determines the structure of generated content:
  - `html`: Returns content as standard HTML markup.
  - `vdom`: Returns content using virtual DOM representation for easier integration with modern frameworks (default).

- **async**: Controls how responses are handled:
  - `await`: The API will wait for processing to complete before returning a response (default).
  - `poll`: Returns immediately with a request ID that can be used to poll for results using a separate endpoint.

#### 5.1.3 Parameters

| Field | Type | Description |
|-------|------|-------------|
| `temperature` | number | Controls randomness (0.0 to 1.0, lower is more deterministic) |
| `max_tokens` | number | Maximum length of the generated response |

### 5.2 Response Fields

| Field | Type | Description |
|-------|------|-------------|
| `id` | string | Unique identifier for the response |
| `created_at` | string | ISO timestamp when the response was generated |
| `response` | object | Container for all response components |

#### 5.2.1 Response Object

| Field | Type | Description |
|-------|------|-------------|
| `completion` | object | New message generated by the model |

#### 5.2.2 Response Content Types

The response can include the following content modes:

| Type | Description | Output Format |
|------|-------------|---------------|
| text | Textual content | Plain text |
| image | Visual content | PNG (URI) |
| audio | Voice recordings | MP3 (URI) |

## 6. Implementation Guidelines

### 6.1 Authentication

The API uses bearer token authentication:

```
Authorization: Bearer YOUR_API_KEY
```

### 6.2 Error Handling

Standard HTTP status codes with detailed error messages:

```json
{
  "error": {
    "code": "invalid_request_error",
    "message": "Message at index 0 has an invalid content type. Only 'text' type is supported for input.",
    "param": "messages[0].content[0].type",
    "type": "validation_error"
  }
}
```

### 6.3 Rate Limiting

- Default: 60 requests per minute
- Headers: X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset

## 7. Code Examples

### 7.1 JavaScript Example

```javascript
async function getEmpathyResponse(userMessage) {
  const response = await fetch('https://api.example.com/v1/empathy/generate', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${API_KEY}`
    },
    body: JSON.stringify({
      model: 'empathy-v1',
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: `${userMessage}`
            }
          ]
        }
      ],
      empathy_options: {
        modes: ['text', 'image']
      },
      parameters: {
        temperature: 0.7,
        max_tokens: 512
      }
    })
  });
  
  return await response.json();
}
```

## 8. Best Practices

### 8.1 Performance Optimization

- Request only the content modes you need (`empathy_options.modes`)
- Set appropriate `max_tokens` values to avoid unnecessary computation

### 8.2 Empathy Guidelines

- Provide sufficient context in the `persona` field to guide the model's persona approach, but do not speak to empathy
- Include relevant conversation history to improve emotional understanding

## 9. Advanced Features

### 9.1 Webhook Callbacks

NOT SUPPORTED

### 9.2 Streaming Responses

NOT SUPPORTED

## 10. Implementation Roadmap

1. **Phase 1**: Text input and multi-modal output (text, image, audio) for echo, enhance, complete messages. Long run response polling.
2. **Phase 2****: Multi-modal input (image, audio)
3. **Phase 3**: Streaming and web-hooks